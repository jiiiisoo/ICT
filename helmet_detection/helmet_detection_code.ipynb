{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_project_code.ipynb",
      "provenance": [],
      "mount_file_id": "1GIreXgkCa4hue69ANig_mM5_Dc2iMEU9",
      "authorship_tag": "ABX9TyOpVSZTmTEKnNf1g4zp7Ca0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiiiisoo/ICT/blob/main/helmet_detection/helmet_detection_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DL3M3HR2QYeX"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential,models,layers\n",
        "from tensorflow.keras.layers import Conv2D,MaxPool2D,Dropout,Flatten,Dense,BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import xml.etree.ElementTree as et\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "\n",
        "import cv2\n",
        "import imutils\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#unzip image data file\n",
        "\n",
        "!unzip -uq \"/content/drive/MyDrive/deeplearning/final_project/archive.zip\" -d \"/content/drive/MyDrive/deeplearning/final_project\""
      ],
      "metadata": {
        "id": "TJsbcyHxRJrY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=[]\n",
        "Y=[]\n",
        "\n",
        "#image 불러오기\n",
        "image_list = os.listdir(\"/content/drive/MyDrive/deeplearning/final_project/images\")\n",
        "label_list = os.listdir(\"/content/drive/MyDrive/deeplearning/final_project/annotations\")\n",
        "\n",
        "print(len(image_list), len(label_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7Na4okDUjCp",
        "outputId": "a36110c3-3f2f-420a-f4ab-9513bbafc7b6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "764 764\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#label: With Helmet=1, Without Helmet=0\n",
        "width=128\n",
        "height=128\n",
        "\n",
        "image_set=[]\n",
        "for img in image_list:\n",
        "    label=[]\n",
        "    classnum = []\n",
        "    xtree = et.parse('/content/drive/MyDrive/deeplearning/final_project/annotations/' + img.split('.')[0] + '.xml')\n",
        "    #size = xtree.find('size')\n",
        "    cv2_image = cv2.imread(os.path.join('/content/drive/MyDrive/deeplearning/final_project/images', img),cv2.IMREAD_COLOR)\n",
        "    resized = cv2.resize(cv2_image, (width,height)) #보통 이미지 축소에는 INTER_AREA 사용\n",
        "\n",
        "    for e in xtree.findall('object'):\n",
        "      name = e.find('name').text\n",
        "      label.append({'name': name,})\n",
        "      if name == 'Without Helmet':\n",
        "        label_num=0\n",
        "      elif name == 'With Helmet':\n",
        "        label_num=1\n",
        "      #name이 둘 다 아닌 경우가 있을 수 있으므로\n",
        "      else:\n",
        "        label_num=2\n",
        "    image_set.append((resized, label_num))\n",
        "    \n",
        "print(len(image_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a3Jlu6eZaoc",
        "outputId": "d66979ed-b97e-40ff-aa33-b5a763c40e42"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "764\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split data into train, test dataset\n",
        "\n",
        "random.shuffle(image_set)\n",
        "\n",
        "train_set, test_set = train_test_split(image_set, test_size=0.2, random_state=1)\n",
        "\n",
        "print(len(train_set), len(test_set))"
      ],
      "metadata": {
        "id": "-v0uvR8wddVn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7c16e30-7ff3-4680-fb61-2c71f6b948b0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "611 153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# image, label 분리\n",
        "train_image=[]\n",
        "train_label=[]\n",
        "test_image=[]\n",
        "test_label=[]\n",
        "\n",
        "for image, label in train_set:\n",
        "  train_image.append(image)\n",
        "  train_label.append(label)\n",
        "\n",
        "for image, label in test_set:\n",
        "  test_image.append(image)\n",
        "  test_label.append(label)\n",
        "\n",
        "#차원 조정 ->>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>왱?!\n",
        "train_image=np.array(train_image).reshape(-1,width,height,1)\n",
        "test_image=np.array(test_image).reshape(-1,width,height,1)\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_image=train_image/255.0\n",
        "\n",
        "#image 증강 통해 overfitting 방지하고자 imagedatagenerator로 이미지 변형\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1/255.0,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    zoom_range=0.4,\n",
        "    horizontal_flip=True)"
      ],
      "metadata": {
        "id": "w3Ryvl-NRmfT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = datagen.flow(train_image, train_label, batch_size=16)\n",
        "test_datagen = datagen.flow(test_image, test_label, batch_size=16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "dpEuDRF_W6mf",
        "outputId": "7b03072a-6b21-4eb9-e2f2-4d4a96d90f16"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-221b305edf8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_datagen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_datagen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow\u001b[0;34m(self, x, y, batch_size, shuffle, sample_weight, seed, save_to_dir, save_prefix, save_format, subset)\u001b[0m\n\u001b[1;32m    894\u001b[0m         \u001b[0msave_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m         \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m         subset=subset)\n\u001b[0m\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m   def flow_from_directory(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, dtype)\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/numpy_array_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, dtype)\u001b[0m\n\u001b[1;32m     87\u001b[0m                              \u001b[0;34m'should have the same length. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                              \u001b[0;34m'Found: x.shape = %s, y.shape = %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                              (np.asarray(x).shape, np.asarray(y).shape))\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             raise ValueError('`x` (images tensor) and `sample_weight` '\n",
            "\u001b[0;31mValueError\u001b[0m: `x` (images tensor) and `y` (labels) should have the same length. Found: x.shape = (1833, 128, 128, 1), y.shape = (611,)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model 구축\n",
        "\n",
        "model=models.Sequential()\n",
        "model.add(layers.Conv2D(128,(3,3),activation='relu',input_shape=(128,128,3)))\n",
        "model.add(layers.MaxPool2D(2,2))\n",
        "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(layers.MaxPool2D(2,2))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Conv2D(32,(3,3),activation='relu'))\n",
        "model.add(layers.MaxPool2D(2,2))\n",
        "model.add(layers.Conv2D(32,(3,3),activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "HRsDmuMfkY6U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a125c404-015d-4e59-e8e5-6ccfc54b6e96"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 126, 126, 128)     3584      \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 63, 63, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 61, 61, 64)        73792     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 30, 30, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 30, 30, 64)        0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 28, 28, 32)        18464     \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 14, 14, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 12, 12, 32)        9248      \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4608)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 4609      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109,697\n",
            "Trainable params: 109,697\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "reference  \n",
        "https://hwiyong.tistory.com/48  \n",
        "https://keras.io/ko/preprocessing/image/  \n",
        "https://yunwoong.tistory.com/127"
      ],
      "metadata": {
        "id": "9UcX-enulnpy"
      }
    }
  ]
}